{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50af4860",
   "metadata": {},
   "source": [
    "This program utilizes Naive Bayesian analysis to assess for a relationship between high- or low-value Jeopardy questions and the textual content of questions and answers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a025e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The natural language toolkit for tokenizing words and sentences\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "#scikit-learn is a key data science module like pandas\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import re\n",
    "import config5\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "\n",
    "english_stopwords = set(stopwords.words('english')+list(punctuation)+['..','...','....','``','//n',\"''\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83099cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elenc\\AppData\\Local\\Temp/ipykernel_8576/2492281559.py:6: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['value'] = df['value'].str.replace(',', '').str.replace('$', '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>air_date</th>\n",
       "      <th>question</th>\n",
       "      <th>value</th>\n",
       "      <th>answer</th>\n",
       "      <th>round</th>\n",
       "      <th>show_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HISTORY</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'For the last 8 years of his life, Galileo was...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'No. 2: 1912 Olympian; football star at Carlis...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'The city of Yuma in this state has a record a...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'In 1963, live on \"The Art Linkletter Show\", t...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>McDonald\\'s</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>'Signer of the Dec. of Indep., framer of the C...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          category    air_date  \\\n",
       "0                          HISTORY  2004-12-31   \n",
       "1  ESPN's TOP 10 ALL-TIME ATHLETES  2004-12-31   \n",
       "2      EVERYBODY TALKS ABOUT IT...  2004-12-31   \n",
       "3                 THE COMPANY LINE  2004-12-31   \n",
       "4              EPITAPHS & TRIBUTES  2004-12-31   \n",
       "\n",
       "                                            question  value       answer  \\\n",
       "0  'For the last 8 years of his life, Galileo was...  200.0   Copernicus   \n",
       "1  'No. 2: 1912 Olympian; football star at Carlis...  200.0   Jim Thorpe   \n",
       "2  'The city of Yuma in this state has a record a...  200.0      Arizona   \n",
       "3  'In 1963, live on \"The Art Linkletter Show\", t...  200.0  McDonald\\'s   \n",
       "4  'Signer of the Dec. of Indep., framer of the C...  200.0   John Adams   \n",
       "\n",
       "       round  show_number  \n",
       "0  Jeopardy!         4680  \n",
       "1  Jeopardy!         4680  \n",
       "2  Jeopardy!         4680  \n",
       "3  Jeopardy!         4680  \n",
       "4  Jeopardy!         4680  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the jeopardy data JSON file\n",
    "with open('jeopardy.json', 'r') as jeopardy:\n",
    "    data=jeopardy.read()\n",
    "\n",
    "df = pd.read_json(StringIO(data))\n",
    "df['value'] = df['value'].str.replace(',', '').str.replace('$', '')\n",
    "df['value'] = pd.to_numeric(df['value'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75aecbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0           9\n",
       "20.0          1\n",
       "22.0          1\n",
       "50.0          1\n",
       "100.0      9029\n",
       "200.0     30455\n",
       "250.0         5\n",
       "300.0      8663\n",
       "350.0         2\n",
       "367.0         1\n",
       "400.0     42244\n",
       "500.0      9016\n",
       "585.0         1\n",
       "600.0     20377\n",
       "601.0         1\n",
       "700.0       203\n",
       "750.0         4\n",
       "796.0         1\n",
       "800.0     31860\n",
       "900.0       114\n",
       "1000.0    21640\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check what our value range looks like\n",
    "value_counts = df['value'].sort_values(axis=0).value_counts(sort=False)\n",
    "value_counts[:1000]\n",
    "\n",
    "# we can see some unusual value figures from double jeopardy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f32a674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anything over 600.0 will be considered a high value question\n",
      "(encompasses 119805 of 216930 answers)\n"
     ]
    }
   ],
   "source": [
    "# locate the dollar amount that is a good midpoint for splitting the range of entries\n",
    "half_of_answers = int(len(df)/2)\n",
    "accumulated_answers=0\n",
    "dollar_threshold=0\n",
    "for dollar_amount, value_count in value_counts.items():\n",
    "    accumulated_answers+=value_count\n",
    "    if accumulated_answers > half_of_answers:\n",
    "        dollar_threshold = dollar_amount\n",
    "        break;\n",
    "\n",
    "print('Anything over '+str(dollar_threshold)+' will be considered a high value question')\n",
    "print ('(encompasses '+str(accumulated_answers)+' of '+str(len(df))+' answers)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c71e5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare value arrays \n",
    "is_high_value = []\n",
    "q_and_a       = []\n",
    "dollar_values = []\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    lemm_text = [lemmatizer.lemmatize(x) for x in word_tokenize((row['question']+' '+row['answer']).lower()) if x not in english_stopwords]\n",
    "    q_and_a.append(' '.join(lemm_text))\n",
    "    if row.value <= 600.0:\n",
    "        is_high_value.append(0)\n",
    "    else:\n",
    "        is_high_value.append(1)\n",
    "    dollar_values.append(row.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e491767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new dataframe using our prepared value arrays\n",
    "df_prepared = pd.DataFrame({\"dollar_value\":dollar_values,\"is_high_value\":is_high_value,\"q_and_a\":q_and_a})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c1e5b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out our train and test subsets\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_prepared.q_and_a, df_prepared.is_high_value, random_state=1)\n",
    "\n",
    "# vectorize the text\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "\n",
    "# getting a whole set of vectors with words and their frequency\n",
    "x_train_tf = tfidf_vectorizer.fit_transform(x_train)\n",
    "\n",
    "# this is our second half from the split that we are preparing to use for prediction with naive bayes\n",
    "x_test_tf = tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b35a27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5972009662013903\n"
     ]
    }
   ],
   "source": [
    "# ask NB to try fitting this with our training data\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(x_train_tf, y_train)\n",
    "\n",
    "# now try to predict for the second half to see if you can get status right\n",
    "predictions = naive_bayes.predict(x_test_tf)\n",
    "\n",
    "# how well did we do?\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print('Accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3fc8f5",
   "metadata": {},
   "source": [
    "We can see that this did not work very well in this case due to the complexity of the relationships involved.  I re-ran it with category included in the textual content out of curiosity and the accuracy was almost identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00f34da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop an output file that indicates the result\n",
    "with open('module 5 basics.txt', 'w') as f:\n",
    "    f.write('Unsuccessful Naive Bayes analysis of $600 +/- value question relationship with question content (accuracy:'+str(accuracy)+\")\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
